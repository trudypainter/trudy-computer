---
title: GEMINI MULTIMODAL LAUNCH
year: 2024
location: Google
description: Promotional (and controversial) videos for Google's biggest AI release to date
image: gemini-launch/handson.avif
tags: machine learning, video
priority: 23
featured: google
link: https://www.latentlab.ai/
---

<Hero>
  <div>
    <Callout
      link={
        'https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/'
      }
      text={'Gemini Blog Post'}
    />
    <Callout
      link={'https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html'}
      text={'Developer Post'}
    />
    <Callout
      link={'https://www.youtube.com/watch?v=UIZAiXYceBI'}
      text={'Hands On'}
    />
    <Callout
      link={'https://www.youtube.com/watch?v=NHLnjWTEZps'}
      text={'Coding Snackable'}
    />
    
  </div>
  <div>
    ![Gemini Multimodal Launch](/gemini-launch/geminiGif3.gif)

    In December 2023, Google launched [Gemini](https://deepmind.google/technologies/gemini/#introduction), a multimodal AI model that could understand and
    generate text, images, and audio.

    I worked on the small team tasked to create a series of promotional videos for the launch.
    Multimodal AI was a new and complex concept, so we had to create a series of videos that would
    explain the technology to a wide audience.

  </div>
</Hero>

<Line />

<TwoCol>
**Hands on with Gemini**

    One of the videos was a 6 minute long demo of the AI in action, that used abridged versions of
    the prompts. I helped with the concepting and production of the video, alongisde a team of 3 other brilliant filmmakers.

    <YouTubeEmbed id="UIZAiXYceBI" />

<Line />

    <TwoCol>
    **Controversy**

    The launch was controversial, with some journalists pointing out that prompts were abridged.

    Google's response to these reports are in this [developer post](https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html).


    </TwoCol>

    ![](/gemini-launch/tc.png)

</TwoCol>

<Line />

<TwoCol>
**Snackable Snippets**

    Another series of videos from the launch were 1 minutes videos that demonstrated novel use cases,
    like [picking an outfit](https://www.youtube.com/watch?v=HP2pNdCRT5M) or [combining different emojis](https://www.youtube.com/watch?v=ki8kRJPXCW0).

 <TwoCol>
 **Coding Snippet**

    I was responsible for concepting, scripting, and voicing the snackable snippet use case video for coding.

    I personally love fractal trees... especially ties between biomimicry and code, so I made a video highlighting
    the model's ability to generate code by bridging patterns across different domains.

    <YouTubeEmbed id="NHLnjWTEZps" />

    </TwoCol>

</TwoCol>
