---
title: GEMINI 1.5 PRO LAUNCH
year: 2024
location: Google
description: Tutorial videos to highlight AI research breakthrough
image: gemini-15/covercrop.avif
tags: machine learning, video
priority: 22
featured: google
link: https://www.latentlab.ai/
---

<Hero>
  <div>
    <Callout
      link={
        'https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#gemini-15'
      }
      text={'Gemini 1.5 Blog Post'}
    />
    <Callout
      link={'https://www.youtube.com/watch?v=LHKL_210CcU'}
      text={'Video Demo'}
    />
  </div>
  <div>

    <video src="/gemini-15/final_tokens_scale_animated_3840x2300.mp4" autoPlay muted loop />

In February of 2024, Google released Gemini 1.5, the next generation of their multimodal model Gemini.

This AI research breakthrough is introducing a new era of long-context understanding and multimodal
processing capabilities. Gemini 1.5's ability to process up to 1 million tokens allows it to
digest and analyze vast amounts of information, from lengthy documents to hours of video, all in a single go.

I collaborated with DeepMind researchers to find effective ways to demonstrate the capabilities of Gemini 1.5.

  </div>
</Hero>

<Line />

<TwoCol>
**Video Demos**

I helped concept, script and voice a series of tutorial videos exploring
use cases leveraging a long context window.

I worked most closely concepting this [three.js coding example](https://www.youtube.com/watch?v=SSnsmqIj1MI).
I also voiced the Apollo 11 transcript demo video below.

<YouTubeEmbed id="LHKL_210CcU" />

</TwoCol>
